{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Solar Panel Image Classification using VGG16"]},{"cell_type":"markdown","metadata":{},"source":["![](https://wallpapercave.com/wp/wp4041905.jpg)"]},{"cell_type":"markdown","metadata":{},"source":["### Objective of this project "]},{"cell_type":"markdown","metadata":{},"source":["The accumulation of dust, snow, bird drops etc. on the surface of solar panels reduces the efficiency of the solar modules and hence the amount of produced energy. Monitoring and cleaning solar panels is a crucial task, hence developing an optimal procedure to monitor and clean these panels is very important in order to increase modules efficiency, reduce maintenance cost and reducing the use of resources.\n","\n","The objective of this project is to investigate the ability of different machine learning classifiers to detect dust, snow, bird drops, physical and electrical on solar panel surfaces with the highest possible accuracy."]},{"cell_type":"markdown","metadata":{},"source":["#### Factors that can cause a reduction in power generation from solar panels "]},{"cell_type":"markdown","metadata":{"id":"LsSz8o9jFXlW","outputId":"251c30fc-0b36-41ae-9e8b-b4c8161e85ec"},"source":["\n","There are a number of factors that can cause a reduction in power generation from solar panels. These include:\n","\n","1. Reduced sunlight: Solar panels generate electricity by converting sunlight into electricity. If there is less sunlight, then there will be less electricity generated. This can happen on cloudy days, during the winter, or in areas with high levels of air pollution.\n","    \n","2. High temperatures: Solar panels are most efficient when they are at a moderate temperature. If the temperature gets too high, then the efficiency of the solar panel will decrease. This is because the heat causes the electrons in the solar cells to move faster, which reduces the amount of energy that is converted into electricity.\n","    \n","3. Dirt and debris: Dirt and debris can block sunlight from reaching the solar panel, which will reduce the amount of electricity that is generated. It is important to clean solar panels regularly to remove any dirt or debris that has accumulated.\n","    \n","4. Degradation: Solar panels will degrade over time, which will reduce their efficiency. The rate of degradation will vary depending on the type of solar panel and the conditions in which it is installed.\n","    \n","5. Inverter failure: The inverter is a device that converts the direct current (DC) electricity generated by the solar panel into alternating current (AC) electricity, which is the type of electricity that is used in homes and businesses. If the inverter fails, then the solar panel will not be able to generate electricity."]},{"cell_type":"markdown","metadata":{},"source":["#### Effects of dirt, debris, snow, bird drop and electrical damage on solar panels health."]},{"cell_type":"markdown","metadata":{},"source":["Here are the effects of dirt, debris, snow, bird drop, mechanical damage and electrical damage on solar panels:\n","    \n","1. Dirt and debris: Dirt and debris can block sunlight from reaching the solar panel, which will reduce the amount of electricity that is generated. It is important to clean solar panels regularly to remove any dirt or debris that has accumulated.\n","    \n","2. Snow: Snow can also block sunlight from reaching the solar panel, but it will usually melt off on its own during the day. If there is a lot of snow, it may be necessary to remove it manually.\n","    \n","3. Bird droppings: Bird droppings can be acidic and can damage the surface of the solar panel. It is important to clean bird droppings off of solar panels as soon as possible.\n","    \n","3. Mechanical damage: Solar panels can be damaged by hail, wind, or other objects. If a solar panel is damaged, it will need to be repaired or replaced.\n","    \n","4. Electrical damage: Solar panels can be damaged by lightning strikes or other electrical surges. If a solar panel is damaged by electrical damage, it will need to be repaired or replaced.\n","\n","Here are some tips to help protect solar panels from damage: \n","    \n","1. Clean the solar panels regularly. This will help to remove any dirt, debris, or bird droppings that may be blocking sunlight from reaching the panels.\n","    \n","2. Install the solar panels in a location that is protected from hail, wind, and other objects. This will help to reduce the risk of mechanical damage.\n","    \n","3. Have solar panels inspected by a qualified professional on a regular basis. This will help to identify any potential problems early on and prevent them from causing further damage.\n"]},{"cell_type":"markdown","metadata":{},"source":["### Deep learning & Solar Panel fault classification "]},{"cell_type":"markdown","metadata":{},"source":["\n","1. Deep learning can be used to classify different types of faults. This is because deep learning models can learn to distinguish between different types of patterns. For example, a deep learning model could be trained to distinguish between the patterns of a cracked panel, a dirty panel, a burned-out panel, bird dropping on solar panel and snow cover on solar panel.\n","\n","2. Deep learning can be used to localize faults. This is because deep learning models can learn to identify the location of a fault within a solar panel. For example, a deep learning model could be trained to identify the location of a cracked panel within a solar plant.\n","\n","4. Deep learning is a powerful tool that can be used to improve the efficiency and reliability of solar panel systems. By identifying and localizing faults early on, deep learning can help to prevent costly repairs and downtime.\n","\n","Here are some of the benefits of using deep learning for solar panel fault detection:\n","\n","1. Accuracy: Deep learning models can achieve high accuracy in detecting faults, even in cases where human inspectors may miss them.**\n","\n","2. Speed: Deep learning models can quickly scan large amounts of data to identify potential faults.\n","\n","3. Scalability: Deep learning models can be easily scaled to handle larger and more complex datasets.\n","\n","4. Cost-effectiveness: Deep learning models can be used to automate the fault detection process, which can save money on labor costs.\n"]},{"cell_type":"markdown","metadata":{},"source":["### About Dataset"]},{"cell_type":"markdown","metadata":{},"source":["This directory contains six different class folders to classify between. Since the images were scraped from the internet, there is a slight imbalance in the number of images collected.\n","\n","\n","1. Clean: This directory has images of clean solar panels\n","2. Dusty: This directory has images of dusty solar panels\n","3. Bird-drop: This directory has images of bird-drop on solar panels\n","\n","4. Electrical-damage: This directory has images of electrical-damage solar panels\n","\n","5. Physical-Damage: This directory has images of physical-damage solar panels\n","\n","6. Snow-Covered: This directory has images of snow-covered on solar panels"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T22:13:37.291333Z","iopub.status.busy":"2023-06-05T22:13:37.290367Z","iopub.status.idle":"2023-06-05T22:13:37.300194Z","shell.execute_reply":"2023-06-05T22:13:37.29905Z","shell.execute_reply.started":"2023-06-05T22:13:37.29128Z"},"id":"QNTT3WfuAXte","trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'seaborn'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m \n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m \n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m \n\u001b[0;32m      5\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"]}],"source":["import pandas as pd \n","import numpy as np \n","import seaborn as sns\n","import matplotlib.pyplot as plt \n","%matplotlib inline \n","\n","import tensorflow as tf\n","import random\n","from cv2 import resize\n","from glob import glob\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T22:15:25.614232Z","iopub.status.busy":"2023-06-05T22:15:25.613244Z","iopub.status.idle":"2023-06-05T22:15:32.581941Z","shell.execute_reply":"2023-06-05T22:15:32.580842Z","shell.execute_reply.started":"2023-06-05T22:15:25.61419Z"},"id":"1RZ_DQqF_MTd","trusted":true},"outputs":[],"source":["img_height = 244\n","img_width = 244\n","train_ds = tf.keras.utils.image_dataset_from_directory(\n","  '/kaggle/input/solar-panel-images/Faulty_solar_panel',\n","  validation_split=0.2,\n","  subset='training',\n","  image_size=(img_height, img_width),\n","  batch_size=32,\n","  seed=42,\n","  shuffle=True)\n","\n","val_ds = tf.keras.utils.image_dataset_from_directory(\n","  '/kaggle/input/solar-panel-images/Faulty_solar_panel',\n","  validation_split=0.2,\n","  subset='validation',\n","  image_size=(img_height, img_width),\n","  batch_size=32,\n","  seed=42,\n","  shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T22:15:39.435997Z","iopub.status.busy":"2023-06-05T22:15:39.435591Z","iopub.status.idle":"2023-06-05T22:15:39.445763Z","shell.execute_reply":"2023-06-05T22:15:39.444545Z","shell.execute_reply.started":"2023-06-05T22:15:39.435966Z"},"id":"SaOQ_-E--XMO","outputId":"51278ed1-8f37-40f4-f511-3654cfc76a08","trusted":true},"outputs":[],"source":["class_names = train_ds.class_names\n","print(class_names)\n","train_ds"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T22:15:43.012025Z","iopub.status.busy":"2023-06-05T22:15:43.011641Z","iopub.status.idle":"2023-06-05T22:15:50.999796Z","shell.execute_reply":"2023-06-05T22:15:50.998467Z","shell.execute_reply.started":"2023-06-05T22:15:43.011995Z"},"id":"1R_-ARdq-hZf","outputId":"7971807f-7b2b-46c2-88ef-2a65addc9362","trusted":true},"outputs":[],"source":["plt.figure(figsize=(15, 15))\n","for images, labels in train_ds.take(1):\n","    for i in range(25):\n","        ax = plt.subplot(5, 5, i + 1)\n","        plt.imshow(images[i].numpy().astype(\"uint8\"))\n","        plt.title(class_names[labels[i]])\n","        plt.axis(\"off\")"]},{"cell_type":"markdown","metadata":{},"source":["### VGG16"]},{"cell_type":"markdown","metadata":{},"source":["VGG16 is a convolutional neural network (CNN) that is widely used for image classification. It was first introduced in 2014 by the Visual Geometry Group (VGG) at the University of Oxford. VGG16 is a deep network, with 16 layers, and it has been shown to be very effective at image classification. It has achieved state-of-the-art results on a number of benchmark datasets, including ImageNet.\n","\n","VGG16 is a popular choice for image classification because it is:\n","\n","1.\tVersatile: VGG16 can be used for a variety of image classification tasks, including object detection, scene classification, and person identification.\n","2.\tAccurate: VGG16 has been shown to be very accurate at image classification, achieving state-of-the-art results on a number of benchmark datasets.\n","3.\tEfficient: VGG16 is relatively efficient, making it a good choice for real-time applications.\n","\n","Here are some of the reasons why we use VGG16:\n","\n","1.\tAccuracy: VGG16 has been shown to be very accurate at image classification, achieving state-of-the-art results on a number of benchmark datasets. For example, on the ImageNet dataset, VGG16 achieves an accuracy of 92.7%.\n","2.\tTransfer learning: VGG16 can be used for transfer learning, which is a technique that allows us to use a pre-trained model to improve the performance of a new model. Transfer learning is often used when we have a small dataset for our new model.\n","3.\tEase of use: VGG16 is available in many deep learning frameworks, such as Keras and TensorFlow. This makes it easy to use for image classification tasks.\n","\n","Overall, VGG16 is a powerful and versatile CNN that is widely used for image classification. It is accurate, efficient, and easy to use.\n","\n","![](https://storage.googleapis.com/lds-media/images/vgg16-architecture.original.jpg)"]},{"cell_type":"markdown","metadata":{},"source":["### Transfer learning & VGG16"]},{"cell_type":"markdown","metadata":{},"source":["Transfer learning is a machine learning technique where a model trained on one task is reused as the starting point for a model on a second task. This can be useful when there is limited data available for the second task, or when the two tasks are related in some way.\n","\n","VGG16 is a convolutional neural network (CNN) that was trained on the ImageNet dataset, which contains over 14 million images and 1000 different classes. VGG16 is a very powerful model, and it can achieve state-of-the-art results on a variety of image classification tasks.\n","\n","To use transfer learning with VGG16, we can start by loading the pre-trained model from a Keras library. We can then freeze the weights of the first few layers of the model, and train the last few layers on our own dataset. This allows us to take advantage of the knowledge that VGG16 has learned on the ImageNet dataset, while still being able to fine-tune the model to our specific task.\n","\n","Transfer learning with VGG16 can be a very effective way to build a machine learning model when there is limited data available. It can also be used to improve the performance of a model when there is a lot of data available, but the data is noisy or imbalanced.\n","\n","Here are some of the advantages of using transfer learning with VGG16:\n","\n","1.\tReduces the amount of training data required. VGG16 has been trained on a massive dataset, so it already has a good understanding of the general features of images. This means that we can train a model on a smaller dataset, which can save time and resources.\n","2.\tImproves the performance of the model. By fine-tuning the last few layers of VGG16 on our own dataset, we can improve the model's performance on our specific task.\n","3.\tIs relatively easy to implement. There are many tutorials available that show how to use transfer learning with VGG16.\n","\n","Here are some of the disadvantages of using transfer learning with VGG16:\n","\n","4.\tMay not be effective if the data is very different from the data that VGG16 was trained on. If the data is very different from the data that VGG16 was trained on, then transfer learning may not be effective. In this case, it may be better to train a model from scratch.\n","5.\tMay not be able to achieve state-of-the-art results. Transfer learning is a powerful technique, but it may not be able to achieve state-of-the-art results on all tasks. If you need to achieve the best possible results, then you may need to train a model from scratch.\n","\n","Overall, transfer learning with VGG16 is a powerful technique that can be used to build machine learning models when there is limited data available. It can also be used to improve the performance of a model when there is a lot of data available, but the data is noisy or imbalanced"]},{"cell_type":"markdown","metadata":{},"source":["![](https://www.researchgate.net/profile/Amir-Mosavi-3/publication/334992074/figure/fig2/AS:788879695179776@1565094984739/VGG-16-model-Illustration-of-using-the-VGG-16-for-transfer-learning-The-convolution.png)"]},{"cell_type":"markdown","metadata":{},"source":["### VGG16 and its limitations"]},{"cell_type":"markdown","metadata":{},"source":["VGG16 has a number of limitations, including:\n","\n","1.\tComputational complexity: VGG16 is a very computationally expensive model to train and deploy. It has a large number of parameters, which requires a lot of data and computation to train. This can make it difficult to use VGG16 on resource-constrained devices, such as mobile phones or embedded systems.\n","2.\tVanishing gradients: VGG16 is prone to the vanishing gradient problem, which can make it difficult to train the model to convergence. This is because the model has a very deep architecture, which can cause the gradients to become very small as they propagate through the network.\n","3.\tOverfitting: VGG16 is prone to overfitting, which can lead to poor performance on unseen data. This is because the model has a large number of parameters, which can make it difficult to generalize to new data.\n","4.\tData requirements: VGG16 requires a large amount of training data to achieve good performance. This can be a challenge, especially for tasks such as object detection and segmentation, which require a large variety of object classes.\n","\n","**Despite these limitations, VGG16 remains a popular model for image classification tasks. It has achieved state-of-the-art results on a number of benchmark datasets, and it is often used as a baseline for other image classification models. However, it is important to be aware of the limitations of VGG16 when using it for real-world applications.**"]},{"cell_type":"markdown","metadata":{},"source":["### Ways to overcome the limitations of VGG16"]},{"cell_type":"markdown","metadata":{},"source":["Here are some of the ways to overcome the limitations of VGG16:\n","\n","1.\tData augmentation: Data augmentation can be used to increase the size of the training dataset and reduce overfitting. This can be done by creating new training examples by applying transformations to the existing data, such as cropping, flipping, and rotating images.\n","2.\tRegularization: Regularization techniques can be used to prevent the model from overfitting. This can be done by adding a penalty to the loss function that penalizes the model for having large weights.\n","3.\tTransfer learning: Transfer learning can be used to train a VGG16 model on a smaller dataset. This is done by pre-training the model on a large dataset, such as ImageNet, and then fine-tuning the model on the smaller dataset.\n","\n","**By using these techniques, it is possible to overcome the limitations of VGG16 and achieve good performance on image classification tasks.**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T22:16:13.878964Z","iopub.status.busy":"2023-06-05T22:16:13.878237Z","iopub.status.idle":"2023-06-05T22:16:14.876365Z","shell.execute_reply":"2023-06-05T22:16:14.875264Z","shell.execute_reply.started":"2023-06-05T22:16:13.878927Z"},"id":"jbyTA_hDF5tL","outputId":"13ead9d9-41e7-489b-87ab-ebb4080afc82","trusted":true},"outputs":[],"source":["base_model = tf.keras.applications.VGG16(\n","    include_top=False,\n","    weights='imagenet',\n","    input_shape=(img_height, img_width, 3)\n",")\n","base_model.trainable = False "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T22:16:19.874438Z","iopub.status.busy":"2023-06-05T22:16:19.874044Z","iopub.status.idle":"2023-06-05T22:16:20.004205Z","shell.execute_reply":"2023-06-05T22:16:20.003427Z","shell.execute_reply.started":"2023-06-05T22:16:19.874372Z"},"id":"CUEDy_7HF5w5","outputId":"e98489dd-2367-430a-a8b5-36477cf5ae30","trusted":true},"outputs":[],"source":["inputs = tf.keras.Input(shape=(img_height, img_width, 3))\n","x = tf.keras.applications.vgg16.preprocess_input(inputs)\n","x = base_model(x, training=False)\n","x = tf.keras.layers.GlobalAveragePooling2D()(x)\n","x = tf.keras.layers.Dropout(0.3)(x)\n","outputs = tf.keras.layers.Dense(90)(x)\n","model = tf.keras.Model(inputs, outputs)\n","\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T22:16:24.182336Z","iopub.status.busy":"2023-06-05T22:16:24.181254Z","iopub.status.idle":"2023-06-05T22:16:24.484319Z","shell.execute_reply":"2023-06-05T22:16:24.483437Z","shell.execute_reply.started":"2023-06-05T22:16:24.182299Z"},"id":"lH09ZAZ67W-D","outputId":"6f88fd8f-a217-4dd1-f5aa-a0a2b5738ea3","trusted":true},"outputs":[],"source":["from keras.utils.vis_utils import plot_model\n","plot_model(model, to_file='cnn_plot.png', show_shapes=True, show_layer_names=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T22:16:32.08609Z","iopub.status.busy":"2023-06-05T22:16:32.08552Z","iopub.status.idle":"2023-06-05T22:16:47.319477Z","shell.execute_reply":"2023-06-05T22:16:47.318392Z","shell.execute_reply.started":"2023-06-05T22:16:32.086053Z"},"id":"BbArpl157mS8","outputId":"a46c3016-fd8a-41bb-c6b6-f7dfad0043e0","trusted":true},"outputs":[],"source":["!pip install visualkeras\n","import visualkeras\n","visualkeras.layered_view(model,legend=True,spacing=50,background_fill = 'white')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T22:17:00.632409Z","iopub.status.busy":"2023-06-05T22:17:00.632032Z","iopub.status.idle":"2023-06-05T22:17:00.647449Z","shell.execute_reply":"2023-06-05T22:17:00.646376Z","shell.execute_reply.started":"2023-06-05T22:17:00.632363Z"},"id":"sDT5SlL2F5zt","trusted":true},"outputs":[],"source":["model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"NtFghWmy9WJr"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T22:17:07.340373Z","iopub.status.busy":"2023-06-05T22:17:07.34003Z","iopub.status.idle":"2023-06-05T22:21:11.54131Z","shell.execute_reply":"2023-06-05T22:21:11.540319Z","shell.execute_reply.started":"2023-06-05T22:17:07.340345Z"},"id":"ScxkTm5KF52o","outputId":"0b9c6351-be08-4663-e7f0-d64a3c979ab6","trusted":true},"outputs":[],"source":["epoch = 15\n","model.fit(train_ds, validation_data=val_ds, epochs=epoch,\n","    callbacks = [\n","        tf.keras.callbacks.EarlyStopping(\n","            monitor=\"val_loss\",\n","            min_delta=1e-2,\n","            patience=3,\n","            verbose=1,\n","            restore_best_weights=True\n","        )\n","    ]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T22:21:13.917873Z","iopub.status.busy":"2023-06-05T22:21:13.917514Z","iopub.status.idle":"2023-06-05T22:21:13.94844Z","shell.execute_reply":"2023-06-05T22:21:13.947625Z","shell.execute_reply.started":"2023-06-05T22:21:13.917847Z"},"id":"trvvSxxjGQcn","outputId":"65523038-5120-42ad-cff1-6d4ef3d913cc","trusted":true},"outputs":[],"source":["# fine tuning\n","base_model.trainable = True\n","for layer in base_model.layers[:14]:\n","    layer.trainable = False\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T22:22:02.883357Z","iopub.status.busy":"2023-06-05T22:22:02.882975Z","iopub.status.idle":"2023-06-05T22:22:02.898236Z","shell.execute_reply":"2023-06-05T22:22:02.897028Z","shell.execute_reply.started":"2023-06-05T22:22:02.883327Z"},"id":"EVKWQ_5YGQfv","trusted":true},"outputs":[],"source":["model.compile(optimizer=tf.keras.optimizers.Adam(0.0001),\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T22:22:10.926537Z","iopub.status.busy":"2023-06-05T22:22:10.926087Z","iopub.status.idle":"2023-06-05T22:24:25.202623Z","shell.execute_reply":"2023-06-05T22:24:25.201406Z","shell.execute_reply.started":"2023-06-05T22:22:10.926501Z"},"id":"-XcszIeHGQjV","outputId":"9de11822-152f-42ba-b278-abb7bba342e8","trusted":true},"outputs":[],"source":["epoch = 15\n","history = model.fit(train_ds, validation_data=val_ds, epochs=epoch,\n","    callbacks = [\n","        tf.keras.callbacks.EarlyStopping(\n","            monitor=\"val_loss\",\n","            min_delta=1e-2,\n","            patience=3,\n","            verbose=1,\n","        )\n","    ]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T22:24:36.306047Z","iopub.status.busy":"2023-06-05T22:24:36.305657Z","iopub.status.idle":"2023-06-05T22:24:37.315788Z","shell.execute_reply":"2023-06-05T22:24:37.314694Z","shell.execute_reply.started":"2023-06-05T22:24:36.306018Z"},"id":"n8UGH01Y9axb","outputId":"bc9351a1-013a-40c4-d4b7-ee3c1854ab41","trusted":true},"outputs":[],"source":["get_ac = history.history['accuracy']\n","get_los = history.history['loss']\n","val_acc = history.history['val_accuracy']\n","val_loss = history.history['val_loss']\n","\n","epochs = range(len(get_ac))\n","plt.plot(epochs, get_ac, 'g', label='Accuracy of Training data')\n","plt.plot(epochs, get_los, 'r', label='Loss of Training data')\n","plt.title('Training data accuracy and loss')\n","plt.legend(loc=0)\n","plt.figure()\n","\n","plt.plot(epochs, get_ac, 'g', label='Accuracy of Training Data')\n","plt.plot(epochs, val_acc, 'r', label='Accuracy of Validation Data')\n","plt.title('Training and Validation Accuracy')\n","plt.legend(loc=0)\n","plt.figure()\n","\n","plt.plot(epochs, get_los, 'g', label='Loss of Training Data')\n","plt.plot(epochs, val_loss, 'r', label='Loss of Validation Data')\n","plt.title('Training and Validation Loss')\n","plt.legend(loc=0)\n","plt.figure()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Result Classification"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T22:24:44.578254Z","iopub.status.busy":"2023-06-05T22:24:44.57783Z","iopub.status.idle":"2023-06-05T22:25:00.687065Z","shell.execute_reply":"2023-06-05T22:25:00.685883Z","shell.execute_reply.started":"2023-06-05T22:24:44.578227Z"},"id":"simjZorQ_Be0","outputId":"7496f54c-a3a6-4e55-f6a6-e65c6f359196","trusted":true},"outputs":[],"source":["loss, accuracy = model.evaluate(val_ds)\n","\n","plt.figure(figsize=(20, 20))\n","for images, labels in val_ds.take(1):\n","    for i in range(16):\n","        ax = plt.subplot(4, 4, i + 1)\n","        plt.imshow(images[i].numpy().astype(\"uint8\"))\n","        predictions = model.predict(tf.expand_dims(images[i], 0))\n","        score = tf.nn.softmax(predictions[0])\n","        if(class_names[labels[i]]==class_names[np.argmax(score)]):\n","            plt.title(\"Actual: \"+class_names[labels[i]])\n","            plt.ylabel(\"Predicted: \"+class_names[np.argmax(score)],fontdict={'color':'green'})\n","            \n","        else:\n","            plt.title(\"Actual: \"+class_names[labels[i]])\n","            plt.ylabel(\"Predicted: \"+class_names[np.argmax(score)],fontdict={'color':'red'})\n","        plt.gca().axes.yaxis.set_ticklabels([])        \n","        plt.gca().axes.xaxis.set_ticklabels([])"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":3365061,"sourceId":5889548,"sourceType":"datasetVersion"}],"dockerImageVersionId":30498,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":4}
